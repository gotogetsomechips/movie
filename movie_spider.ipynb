{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "from csv import writer\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.82 Safari/537.36',\n",
    "    'cookie': 'bid=3sjUyZu9BhY; douban-fav-remind=1; viewed=\"1007305\"; _pk_id.100001.4cf6=fe0c750fe7d5ebcc.1732548765.; __yadk_uid=3y2FwpVwXLd6GATDtwe9eh3G63rXgVvW; ll=\"118096\"; _vwo_uuid_v2=D4DE1E32F6CDDB3CABACBC07C7B7AAD0A|4d1e71856bd86a1584f8a9ea79f4b2ff; push_noty_num=0; push_doumail_num=0; _cc_id=bf9e7c5bfcf0ed75d27c4d16d3ce1601; _ga=GA1.2.1068251831.1736592634; _ga_Y4GN1R87RG=GS1.1.1736596766.2.0.1736596766.0.0.0; __utmv=30149280.18192; __utmz=30149280.1737736843.11.8.utmcsr=cn.bing.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmz=223695111.1737736843.9.6.utmcsr=cn.bing.com|utmccn=(referral)|utmcmd=referral|utmcct=/; dbcl2=\"181926153:/OhktQsTDnw\"; panoramaId_expiry=1739340770924; panoramaId=1538ceb9a89ae22e4b5caad643cfa9fb927a5e68f9f8a016d8642467ea14a965; panoramaIdType=panoDevice; __gads=ID=35042766bd7ede1e:T=1736346898:RT=1739255053:S=ALNI_MYaCIiZpgN-8ULWSWtEbHhDXuCdEg; __gpi=UID=00000fb1bdf1c178:T=1736346898:RT=1739255053:S=ALNI_Mag95R6tJEOb80jn_SWEPDjr6CHcg; __eoi=ID=70358b6f5ef27592:T=1736346898:RT=1739255053:S=AA-AfjbtOT9g2EmShnzX2bpo3AEi; FCNEC=%5B%5B%22AKsRol_usVaqL2YHzgMekBu_syJ6DUOMicT6kVaUF6LjhZTHfA-AxwIQG1YYjJaQMpcEBkJ2sKCVfJOzji8EIlkh4ByRWfd7UBRa-tM9FJtFKCSxdLoMI34ndyugbfGSSZOE5Z2qsPEiZgR74SA-8I_VMaO85MZPPw%3D%3D%22%5D%5D; ck=d2Qp; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1739266827%2C%22https%3A%2F%2Fcn.bing.com%2F%22%5D; _pk_ses.100001.4cf6=1; __utma=30149280.799383041.1726306427.1739252183.1739266828.14; __utmb=30149280.0.10.1739266828; __utmc=30149280; __utma=223695111.1512467655.1732548765.1739252186.1739266828.12; __utmb=223695111.0.10.1739266828; __utmc=223695111; frodotk_db=\"d77f5cf912308a00867e16eb36919e00\"'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建保存目录\n",
    "directory = \"电影短评\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "# 创建保存目录\n",
    "directorys = \"电影详情\"\n",
    "if not os.path.exists(directorys):\n",
    "    os.makedirs(directorys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_ids(num_ids=150):\n",
    "    \"\"\"获取电影ID列表\"\"\"\n",
    "    movie_ids = set()\n",
    "    \n",
    "    page = 0\n",
    "    while len(movie_ids) < num_ids:\n",
    "        try:\n",
    "            urls = [\n",
    "                f'https://movie.douban.com/j/search_subjects?type=movie&tag=热门&sort=recommend&page_limit=20&page_start={page}',\n",
    "                f'https://movie.douban.com/j/search_subjects?type=movie&tag=最新&sort=time&page_limit=20&page_start={page}',\n",
    "                f'https://movie.douban.com/j/search_subjects?type=movie&tag=经典&sort=rank&page_limit=20&page_start={page}'\n",
    "            ]\n",
    "            \n",
    "            for url in urls:\n",
    "                response = requests.get(url, headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    for movie in data.get('subjects', []):\n",
    "                        movie_ids.add(movie['id'])\n",
    "                        \n",
    "                        if len(movie_ids) >= num_ids:\n",
    "                            break\n",
    "                \n",
    "                time.sleep(random.uniform(1, 2))\n",
    "            \n",
    "            page += 20\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"获取电影ID时出错: {e}\")\n",
    "            time.sleep(3)\n",
    "            continue\n",
    "            \n",
    "        if page > 200:\n",
    "            break\n",
    "    \n",
    "    return list(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_star_rating(field):\n",
    "    stars = {\n",
    "        'allstar10': '1星',\n",
    "        'allstar20': '2星',\n",
    "        'allstar30': '3星',\n",
    "        'allstar40': '4星',\n",
    "        'allstar50': '5星'\n",
    "    }\n",
    "    return stars.get(field, '未评分')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(movie_ID):\n",
    "    url = f'https://movie.douban.com/subject/{movie_ID}/comments'\n",
    "    res = requests.get(url, headers=headers)\n",
    "    bs = BeautifulSoup(res.text, 'html.parser')\n",
    "    return bs.find('h1').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(comment, writer):\n",
    "    info = comment.find('span', {'class': 'comment-info'})\n",
    "    data_dict = {\n",
    "        \"用户名\": info.find('a').get_text().strip(),\n",
    "        \"评论时间\": info.find('span', {'class': 'comment-time'}).get_text().strip(),\n",
    "        \"IP属地\": info.find('span', {'class': 'comment-location'}).get_text().strip(),\n",
    "        \"评论分数\": get_star_rating(info.find_all('span')[1]['class'][0]),\n",
    "        \"有用数量\": comment.find('span', {'class': 'votes vote-count'}).get_text().strip(),\n",
    "        \"短评内容\": comment.find('span', {'class': 'short'}).get_text().replace('\\n', '').strip().replace('\\r', '').replace('\\t', ''),\n",
    "    }\n",
    "    \n",
    "    global short_count\n",
    "    short_count += 1\n",
    "\n",
    "    print(f\"当前评论数量：{short_count}\\n\",\n",
    "          f\"用户名：{data_dict['用户名']}\\n\",\n",
    "          f\"评论时间：{data_dict['评论时间']}\\n\",\n",
    "          f\"IP属地：{data_dict['IP属地']}\\n\",\n",
    "          f\"评论分数：{data_dict['评论分数']}\\n\",\n",
    "          f\"有用数量：{data_dict['有用数量']}\\n\",\n",
    "          f\"短评内容：{data_dict['短评内容']}\\n\")\n",
    "    \n",
    "    try:\n",
    "        writer.writerow(data_dict)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"保存评论时出错: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(movie_ID):\n",
    "    \"\"\"获取电影评论\"\"\"\n",
    "    page_count = 0\n",
    "    next_url = ''\n",
    "    \n",
    "    while True and short_count < 100:\n",
    "        time.sleep(2)\n",
    "        url = f'https://movie.douban.com/subject/{movie_ID}/comments{next_url}'\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers)\n",
    "            bs = BeautifulSoup(res.text, 'html.parser')\n",
    "            page = bs.find('div', {'id': 'comments'})\n",
    "            \n",
    "            if page is None:\n",
    "                if short_count == 0:\n",
    "                    return False\n",
    "                break\n",
    "                \n",
    "            comments = page.find_all('div', {'class': \"comment-item\"})\n",
    "            for comment in comments:\n",
    "                if short_count >= 100:\n",
    "                    return True\n",
    "                save_data(comment, comment_writer)\n",
    "            \n",
    "            print('====================爬取page{}完毕==================='.format(page_count))\n",
    "            page_count += 1\n",
    "            \n",
    "            try:\n",
    "                next_url = page.find('div', {'id': 'paginator', 'class': 'center'}).find('a', {'data-page': 'next', 'class': 'next'}).attrs[\"href\"]\n",
    "            except:\n",
    "                print('爬取完毕')\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"获取评论时出错: {e}\")\n",
    "            if short_count == 0:\n",
    "                return False\n",
    "            break\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existing_movies():\n",
    "    \"\"\"检查已存在的电影CSV文件\"\"\"\n",
    "    successful_count = 0\n",
    "    existing_names = set()\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            try:\n",
    "                with open(os.path.join(directory, filename), 'r', encoding='utf-8-sig') as f:\n",
    "                    reader = csv.reader(f)\n",
    "                    next(reader)  # 跳过标题行\n",
    "                    comment_count = sum(1 for _ in reader)\n",
    "                    if comment_count >= 100:\n",
    "                        successful_count += 1\n",
    "                        existing_names.add(filename[:-4])  # 去掉.csv后缀\n",
    "                        print(f\"已验证电影 {filename[:-4]} 的数据完整性\")\n",
    "            except Exception as e:\n",
    "                print(f\"验证电影 {filename} 时出错: {e}\")\n",
    "    \n",
    "    return successful_count, existing_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(movies, filename='movies.json'):\n",
    "    \"\"\"保存电影详情到JSON文件\"\"\"\n",
    "    filepath = os.path.join(directorys, filename)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(movies, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_details(movie_id):\n",
    "    \"\"\"获取电影详情\"\"\"\n",
    "    url = f'https://movie.douban.com/subject/{movie_id}/'\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 获取标题\n",
    "        title = soup.find('span', property='v:itemreviewed').text.strip()\n",
    "        \n",
    "        # 获取评分\n",
    "        rating = soup.find('strong', property='v:average').text.strip()\n",
    "        \n",
    "        # 获取制片国家/地区\n",
    "        info = soup.find('div', {'id': 'info'}).text\n",
    "        country_start = info.find('制片国家/地区:') + len('制片国家/地区:')\n",
    "        country_end = info.find('\\n', country_start)\n",
    "        countries = info[country_start:country_end].strip()\n",
    "        \n",
    "        # 获取类型\n",
    "        genres = []\n",
    "        genre_spans = soup.find_all('span', property='v:genre')\n",
    "        for span in genre_spans:\n",
    "            genres.append(span.text.strip())\n",
    "        \n",
    "        return {\n",
    "            'title': title,\n",
    "            'rating': rating,\n",
    "            'countries': countries,\n",
    "            'genres': genres \n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"获取电影 {movie_id} 详情时出错: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 获取电影ID\n",
    "    movie_ids = get_movie_ids(150)\n",
    "    movies = []\n",
    "    \n",
    "    print(f\"开始获取 {len(movie_ids)} 部电影的详情\")\n",
    "    \n",
    "    for i, movie_id in enumerate(movie_ids, 1):\n",
    "        print(f\"\\n正在处理第 {i} 部电影 (ID: {movie_id})\")\n",
    "        \n",
    "        details = get_movie_details(movie_id)\n",
    "        if details:\n",
    "            movies.append(details)\n",
    "            print(f\"成功获取电影信息: {details['title']}\")\n",
    "            print(f\"类型: {', '.join(details['genres'])}\")  # 打印类型信息\n",
    "        \n",
    "        # 随机延时\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    # 保存结果\n",
    "    save_to_json(movies)\n",
    "    print(f\"\\n完成! 共获取 {len(movies)} 部电影的详情\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 检查已有的电影数据\n",
    "    successful_movies, existing_names = check_existing_movies()\n",
    "    print(f\"已找到 {successful_movies} 部完整电影数据\")\n",
    "    \n",
    "    if successful_movies >= 100:\n",
    "        print(\"已经完成100部电影的数据收集\")\n",
    "        exit(0)\n",
    "    \n",
    "    # 获取新的电影ID\n",
    "    remaining_movies = 100 - successful_movies\n",
    "    all_movie_ids = get_movie_ids(remaining_movies + 50)  # 多获取一些作为备用\n",
    "    current_index = 0\n",
    "    \n",
    "    while successful_movies < 100 and current_index < len(all_movie_ids):\n",
    "        movie_ID = all_movie_ids[current_index]\n",
    "        current_index += 1\n",
    "        \n",
    "        try:\n",
    "            # 获取电影名称\n",
    "            name = get_name(movie_ID)\n",
    "            print(f\"\\n开始处理电影: {name}\")\n",
    "            \n",
    "            # 检查是否已经存在相同名称的电影\n",
    "            if name in existing_names:\n",
    "                print(f\"跳过重复电影: {name}\")\n",
    "                continue\n",
    "            \n",
    "            # 获取评论\n",
    "            short_count = 0\n",
    "            comment_file = os.path.join(directory, f\"{name}.csv\")\n",
    "            \n",
    "            with open(comment_file, 'w', encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "                header = [\"用户名\", \"评论时间\", \"IP属地\", \"评论分数\", \"有用数量\", \"短评内容\"]\n",
    "                comment_writer = csv.DictWriter(f, header)\n",
    "                comment_writer.writeheader()\n",
    "                print(f'==============正在爬取{name}短评====================')\n",
    "                \n",
    "                if get_comments(movie_ID):\n",
    "                    successful_movies += 1\n",
    "                    existing_names.add(name)\n",
    "                    print(f\"成功获取第 {successful_movies} 部电影的数据\")\n",
    "                else:\n",
    "                    print(f\"跳过电影 {name}，无法获取评论\")\n",
    "                    # 删除空的CSV文件\n",
    "                    if os.path.exists(comment_file):\n",
    "                        os.remove(comment_file)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"处理电影ID {movie_ID} 时出错: {e}\")\n",
    "            continue\n",
    "        \n",
    "        time.sleep(random.uniform(2, 4))\n",
    "    \n",
    "    print(f\"\\n最终成功获取 {successful_movies} 部电影的数据\")\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
