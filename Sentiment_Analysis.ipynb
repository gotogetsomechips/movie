{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子，确保结果可复现\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 数据加载和预处理\n",
    "def load_csv_files(directory):\n",
    "    \"\"\"加载目录下所有CSV文件并合并\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_data.append(df)\n",
    "            print(f\"加载文件: {filename}, 行数: {len(df)}\")\n",
    "    \n",
    "    if all_data:\n",
    "        merged_df = pd.concat(all_data, ignore_index=True)\n",
    "        print(f\"合并后总行数: {len(merged_df)}\")\n",
    "        return merged_df\n",
    "    else:\n",
    "        print(\"没有找到CSV文件\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清洗\n",
    "def clean_data(df):\n",
    "    \"\"\"对数据进行基本清洗\"\"\"\n",
    "    # 删除缺失值\n",
    "    df = df.dropna(subset=['短评内容'])\n",
    "    \n",
    "    # 打印列名以便调试\n",
    "    print(\"DataFrame 列名:\", df.columns.tolist())\n",
    "    \n",
    "    # 假设评分列为'评分'，将其转换为情感标签\n",
    "    if '评分' in df.columns:\n",
    "        df['情感标签'] = df['评分'].apply(lambda x: 0 if x <= 2 else (1 if x == 3 else 2))\n",
    "    else:\n",
    "        # 如果没有'评分'列，可以考虑以下几种方案:\n",
    "        \n",
    "        # 方案1: 假设另有一个可能的评分列，比如'rating'或'score'\n",
    "        for possible_rating_col in ['rating', 'score', 'rate', '打分', '星级']:\n",
    "            if possible_rating_col in df.columns:\n",
    "                print(f\"使用 '{possible_rating_col}' 列作为评分\")\n",
    "                df['情感标签'] = df[possible_rating_col].apply(lambda x: 0 if x <= 2 else (1 if x == 3 else 2))\n",
    "                return df\n",
    "        \n",
    "        # 方案2: 如果没有任何评分列，可以通过简单的规则从文本中推断情感\n",
    "        print(\"未找到评分列，使用简单文本分析推断情感\")\n",
    "        # 定义一些简单的正面和负面词语\n",
    "        pos_words = ['好', '喜欢', '棒', '赞', '精彩', '感动', '推荐', '经典']\n",
    "        neg_words = ['差', '失望', '烂', '无聊', '难看', '垃圾', '后悔', '浪费']\n",
    "        \n",
    "        def infer_sentiment(text):\n",
    "            pos_count = sum(1 for word in pos_words if word in text)\n",
    "            neg_count = sum(1 for word in neg_words if word in text)\n",
    "            \n",
    "            if pos_count > neg_count:\n",
    "                return 2  # 正面\n",
    "            elif neg_count > pos_count:\n",
    "                return 0  # 负面\n",
    "            else:\n",
    "                return 1  # 中性\n",
    "        \n",
    "        df['情感标签'] = df['短评内容'].apply(infer_sentiment)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 基于TF-IDF的情感分析\n",
    "class TFIDFAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000)\n",
    "        self.model = LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced')\n",
    "    \n",
    "    def preprocess_text(self, texts):\n",
    "        \"\"\"预处理文本\"\"\"\n",
    "        processed_texts = []\n",
    "        for text in texts:\n",
    "            # 分词\n",
    "            words = jieba.cut(text)\n",
    "            # 转换为字符串\n",
    "            processed_text = ' '.join(words)\n",
    "            processed_texts.append(processed_text)\n",
    "        return processed_texts\n",
    "    \n",
    "    def train(self, train_texts, train_labels, val_texts, val_labels):\n",
    "        \"\"\"训练模型\"\"\"\n",
    "        print(\"预处理训练文本...\")\n",
    "        processed_train_texts = self.preprocess_text(train_texts)\n",
    "        \n",
    "        print(\"提取TF-IDF特征...\")\n",
    "        X_train = self.vectorizer.fit_transform(processed_train_texts)\n",
    "        \n",
    "        print(\"训练逻辑回归模型...\")\n",
    "        self.model.fit(X_train, train_labels)\n",
    "        \n",
    "        print(\"预处理验证文本...\")\n",
    "        processed_val_texts = self.preprocess_text(val_texts)\n",
    "        \n",
    "        print(\"转换验证集特征...\")\n",
    "        X_val = self.vectorizer.transform(processed_val_texts)\n",
    "        \n",
    "        print(\"模型预测...\")\n",
    "        val_preds = self.model.predict(X_val)\n",
    "        \n",
    "        return val_labels, val_preds\n",
    "    \n",
    "    def predict(self, texts):\n",
    "        \"\"\"使用训练好的模型进行预测\"\"\"\n",
    "        processed_texts = self.preprocess_text(texts)\n",
    "        X = self.vectorizer.transform(processed_texts)\n",
    "        predictions = self.model.predict(X)\n",
    "        \n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
